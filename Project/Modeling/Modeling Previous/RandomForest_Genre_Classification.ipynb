{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c20498",
   "metadata": {},
   "source": [
    "\n",
    "# Spotify Genre Classification with Random Forest\n",
    "\n",
    "**Project Context**: This project builds a recommendation system for Spotify tracks based on their audio features. The focus is on identifying genre patterns—specifically `mpb`, `rock`, and `death metal`—using a Random Forest model trained on a dataset sourced from Kaggle.\n",
    "\n",
    "**Key Goal**:  \n",
    "- Train a Random Forest classifier with 100 trees.  \n",
    "- Identify the best-performing decision tree in the forest.  \n",
    "- Extract and visualize the most significant genre-splitting thresholds.  \n",
    "- Highlight nodes: 1 (mostly rock), 86 (mpb and death metal), 87 (mostly death metal), 136 (mostly mpb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b487b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, log_loss\n",
    "from sklearn.tree import _tree, plot_tree\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import joblib\n",
    "from models_and_utils.tree_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c6820",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data for Modeling/MPBROCKMETAL_KGsubset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986eea1",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Preparation\n",
    "\n",
    "- Select audio feature columns for model input.\n",
    "- Normalize features.\n",
    "- Encode genre labels.\n",
    "- Split the data into training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdab340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.iloc[:, 6:20]\n",
    "y = df[\"track_genre\"]\n",
    "feature_names = X.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ef56b",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Train Random Forest\n",
    "\n",
    "- Train a Random Forest with 100 trees.\n",
    "- Use `entropy` as the splitting criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, criterion=\"entropy\")\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233e324",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Identify the Best Tree\n",
    "\n",
    "- Compare accuracy of each individual tree on test data.\n",
    "- Select the one with the highest accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d526da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0\n",
    "best_tree_index = 0\n",
    "\n",
    "for i, tree in enumerate(clf.estimators_):\n",
    "    y_pred = tree.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_tree_index = i\n",
    "\n",
    "print(f\"Best tree index (accuracy): {best_tree_index}\")\n",
    "print(f\"Best tree accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "best_tree = clf.estimators_[best_tree_index]\n",
    "\n",
    "rules = extract_rules(\n",
    "    tree=best_tree,\n",
    "    feature_names=X_train.columns,\n",
    "    X_data=X_train,\n",
    "    index_data=X_train.index\n",
    ")\n",
    "rules_df = pd.DataFrame(rules)\n",
    "rules_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e5c3d",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_pred = clf.predict(X_test)\n",
    "tree_pred = best_tree.predict(X_test)\n",
    "\n",
    "forest_acc = accuracy_score(y_test, forest_pred)\n",
    "tree_acc = accuracy_score(y_test, tree_pred)\n",
    "\n",
    "forest_probs = clf.predict_proba(X_test)\n",
    "tree_probs = best_tree.predict_proba(X_test)\n",
    "\n",
    "forest_logloss = log_loss(y_test, forest_probs, labels=range(len(class_labels)))\n",
    "tree_logloss = log_loss(y_test, tree_probs, labels=range(len(class_labels)))\n",
    "\n",
    "print(f\"Random Forest accuracy: {forest_acc:.4f}\")\n",
    "print(f\"Best Tree accuracy:     {tree_acc:.4f}\")\n",
    "print(f\"Random Forest log loss: {forest_logloss:.4f}\")\n",
    "print(f\"Best Tree log loss:     {tree_logloss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3f60d",
   "metadata": {},
   "source": [
    "## 5. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_decoded = label_encoder.inverse_transform(y_encoded)\n",
    "\n",
    "cm = confusion_matrix(y_test, tree_pred)\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', cbar=True,\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff0650",
   "metadata": {},
   "source": [
    "## 6. Visualize Best Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e80caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_labels = label_encoder.inverse_transform(y_encoded)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "plt.figure(figsize=(80, 40))  \n",
    "plot_tree(best_tree,\n",
    "          feature_names=feature_names,\n",
    "          class_names=class_names,  \n",
    "          filled=True,\n",
    "          node_ids=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title(\"Decision Tree - Matplotlib Visualization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6cce1",
   "metadata": {},
   "source": [
    "## 7. Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(best_tree.feature_importances_, index=X.columns)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1e52b",
   "metadata": {},
   "source": [
    "## 8. Extract Specific Rules (Nodes 1, 86, 87, 136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "specific_rules = pd.concat([\n",
    "    rules_df.loc[rules_df[\"node\"] == 1],\n",
    "    rules_df.loc[rules_df[\"node\"] == 86],\n",
    "    rules_df.loc[rules_df[\"node\"] == 87],\n",
    "    rules_df.loc[rules_df[\"node\"] == 136]\n",
    "])\n",
    "print(specific_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251510f",
   "metadata": {},
   "source": [
    "## 9. Visualize Key Thresholds for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_specific_thresholds(df, specific_rules, index_col=\"index\", scatter_color='blue'):\n",
    "    n_rules = len(specific_rules)\n",
    "\n",
    "    n_cols = 2\n",
    "    n_rows = int(np.ceil(n_rules / n_cols))\n",
    "\n",
    "    fig = plt.figure(figsize=(6 * n_cols, 4 * n_rows))\n",
    "    gs = GridSpec(n_rows, n_cols, figure=fig)\n",
    "\n",
    "    for plot_idx, (_, rule) in enumerate(specific_rules.iterrows()):\n",
    "        feature = rule['feature']\n",
    "        threshold = rule['threshold']\n",
    "        data_indices = rule['data_indices']\n",
    "\n",
    "        mask = df[index_col].isin(data_indices)\n",
    "        subset = df.loc[mask]\n",
    "        subset = subset.set_index(index_col).loc[data_indices].reset_index()\n",
    "\n",
    "        x = subset[feature].values\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "\n",
    "        ax = fig.add_subplot(gs[plot_idx])\n",
    "        x_min, x_max = x.min() - 0.1 * abs(x.min()), x.max() + 0.1 * abs(x.max())\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.scatter(x, np.zeros_like(x), color=scatter_color, edgecolor='k', s=30, alpha=0.7)\n",
    "        ax.axvline(x=threshold, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f'Node {rule[\"node\"]} - {feature} ≤ {threshold:.3f}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_specific_thresholds(X.reset_index(), specific_rules)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
